{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQaGZYD+ZRx5lY6mnSfNKu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anil951/Early-detection-of-mental-health/blob/main/implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jJJdMxxB4Xz",
        "outputId": "a4c0143e-9c92-431d-aeae-43af5782177e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------EARLY DETECTION OF MENTAL HEALTH ISSUES IN ADOLESCENTS SYSTEM------------------------\n",
            "\n",
            "\n",
            "WE ARE DEALING IN 3 STAGES\n",
            "\n",
            "\n",
            "in STAGE-1: All the social media platform data of the user is collected and analysed with our trained model- \n",
            "to get NORMAL/NOT NORMAL in corresponding to MENTAL HEALTH - a score will be assigned\n",
            "\n",
            "in STAGE-2: The use shoudl give us his/her recent exam scores and remarks given by the teachers/mentors - \n",
            "our trained model will evaluate and assign a score\n",
            "\n",
            "in STAGE-3: The use can submit his health record scans \n",
            "\n",
            "\n",
            "------------IN FINAL WE GIVE ANY RECOMMENDATIONS BASED ON OUR RESULTS------------\n"
          ]
        }
      ],
      "source": [
        "print(\"-----------------EARLY DETECTION OF MENTAL HEALTH ISSUES IN ADOLESCENTS SYSTEM------------------------\")\n",
        "\n",
        "print(\"\\n\\nWE ARE DEALING IN 3 STAGES\\n\\n\")\n",
        "\n",
        "print(\"in STAGE-1: All the social media platform data of the user is collected and analysed with our trained model- \")\n",
        "print(\"to get NORMAL/NOT NORMAL in corresponding to MENTAL HEALTH - a score will be assigned\\n\")\n",
        "print(\"in STAGE-2: The use shoudl give us his/her recent exam scores and remarks given by the teachers/mentors - \")\n",
        "print(\"our trained model will evaluate and assign a score\\n\")\n",
        "print(\"in STAGE-3: The use can submit his health record scans \")\n",
        "\n",
        "print(\"\\n\\n------------IN FINAL WE GIVE ANY RECOMMENDATIONS BASED ON OUR RESULTS------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STAGE 1\n",
        "\n",
        "# COLLECTING USER SOCIAL MEDIA DATA (for prototype purpose we are using REDDIT AND WHATSAPP CHATS)\n"
      ],
      "metadata": {
        "id": "3JwOK5f7CAKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# COLLECTING USER INTERACTION DATA FROM REDDIT (comments the user has done & the hashtags he/she has been using)"
      ],
      "metadata": {
        "id": "-yi6TOPUCEBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install asyncpraw\n",
        "\n",
        "import asyncpraw\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "# Allow nested event loops in Jupyter notebooks (including Google Colab)\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Create global variables to store user data and subreddit info\n",
        "data = []\n",
        "subreddits = {}\n",
        "\n",
        "# Create a function to fetch user data asynchronously\n",
        "async def fetch_user_data(username):\n",
        "    async with asyncpraw.Reddit(\n",
        "        client_id='gPWNZxE-hepzoXXwx2GcOQ',  # Replace with your actual Client ID\n",
        "        client_secret='vrQVQDP3y5G-uogU7seq6wa-PgfFZQ',  # Replace with your actual client secret\n",
        "        user_agent='MentalHealthAnalyzer/0.1',\n",
        "    ) as reddit:\n",
        "        user = await reddit.redditor(username)\n",
        "\n",
        "        global data, subreddits  # Declare that we are using global variables\n",
        "\n",
        "        user_data = []  # List to hold user comments\n",
        "        subreddit_info = {}  # Dictionary to hold subreddit names and descriptions\n",
        "\n",
        "        # Fetch comments from the user with a limit of 20\n",
        "        async for comment in user.comments.new(limit=20):\n",
        "            subreddit = comment.subreddit\n",
        "            await subreddit.load()  # Load subreddit details to access all attributes\n",
        "\n",
        "            # Add the comment details to user_data\n",
        "            user_data.append(comment.body)  # Store only the comment body\n",
        "\n",
        "            # Store subreddit info if not already stored\n",
        "            if subreddit.display_name not in subreddit_info:\n",
        "                subreddit_info[subreddit.display_name] = subreddit.public_description\n",
        "\n",
        "        # Assign the fetched data to global variables\n",
        "        data = user_data\n",
        "        subreddits = subreddit_info\n",
        "\n",
        "# Create a function to run the async code\n",
        "async def main():\n",
        "    username_input = input(\"Enter Reddit username: \")\n",
        "    await fetch_user_data(username_input)\n",
        "\n",
        "# Run the main function\n",
        "await main()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame for comments\n",
        "reddit_comments_df = pd.DataFrame(data, columns=['Comment'])\n",
        "\n",
        "# Display Comments DataFrame\n",
        "print(\"Comments DataFrame:\")\n",
        "print(reddit_comments_df)\n",
        "\n",
        "# Create a DataFrame for only subreddit descriptions\n",
        "subreddits_df = pd.DataFrame(list(subreddits.values()), columns=['Description'])\n",
        "\n",
        "# Display Subreddits DataFrame\n",
        "print(\"\\nSubreddit Descriptions DataFrame:\")\n",
        "print(subreddits_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8n82ysXuCFh5",
        "outputId": "12a7dd64-ff5e-4669-9d98-79be18f3f7d0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Reddit username: cats\n",
            "Comments DataFrame:\n",
            "                                              Comment\n",
            "0                                                Very\n",
            "1   Take it as a $10k lesson and move on.\\n\\nIâ€™d s...\n",
            "2                                                Both\n",
            "3   CRO has two chains actually. Crypto.com chain ...\n",
            "4   [https://leaderboard.bitfinex.com/](https://le...\n",
            "5   Everyone buys shit to sell later at a higher p...\n",
            "6   People love fun. NFTs are fun. End of discussion.\n",
            "7   It will hit 63k, 100k, and eventually 500k. Th...\n",
            "8   How does burning a fee turn a currency into a ...\n",
            "9   Scam. The actual website is lostpoets.xyz.\\n\\n...\n",
            "10                       Nano has no smart contracts.\n",
            "11  You will see old lockers under \"Archives\".\\n\\n...\n",
            "12                                               USDC\n",
            "13  PancakeSwap if you're willing to put liquidity...\n",
            "14  SafeMoon killer is here guys. Invest or get le...\n",
            "15  Better than GhostFace and HODL. Love the auto ...\n",
            "16  Great team. Very active in chat and got big pl...\n",
            "17  I am in. Devs are based. Listen to community, ...\n",
            "18                                  LFGGGGGGGGGGGGGGG\n",
            "19                                    LFGGGGGGGGGGGG!\n",
            "\n",
            "Subreddit Descriptions DataFrame:\n",
            "                                         Description\n",
            "0  r/AskReddit is the place to ask and answer tho...\n",
            "1  The leading community for cryptocurrency news,...\n",
            "2  This subreddit is a place to discuss low marke...\n",
            "3  This is a community run group for DxSale. This...\n",
            "4  BSC Moonshots! Made for the underground moonsh...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COLLECTING USER INTERACTION DATA FROM WHATSAPP (Userchats with most frequent)"
      ],
      "metadata": {
        "id": "mDpO_UJbCQgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of file paths (add each file path here)\n",
        "file_paths = [\n",
        "    \"/content/chat.txt\",\n",
        "    \"/content/chat2.txt\",\n",
        "]\n",
        "\n",
        "try:\n",
        "    # Initialize an empty list to store all messages\n",
        "    all_messages = []\n",
        "\n",
        "    # Loop through each file and process\n",
        "    for file_path in file_paths:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            messages = file.readlines()\n",
        "\n",
        "        # Process each message to extract only the content after ': '\n",
        "        for msg in messages:\n",
        "            if ': ' in msg:\n",
        "                content = msg.split(': ', 1)[1].strip()  # Get everything after the first ': '\n",
        "                all_messages.append(content)\n",
        "\n",
        "    # Create a DataFrame from the collected messages\n",
        "    wasap_msg_df = pd.DataFrame(all_messages, columns=['msg'])\n",
        "\n",
        "    print(\"First few rows of the combined DataFrame:\")\n",
        "    print(wasap_msg_df.head())\n",
        "    print(\"\\nTotal number of messages:\", len(wasap_msg_df))\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"File not found: {e.filename}\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fmbrWkMCRez",
        "outputId": "b6447444-0f17-4208-918d-0caf3c6a6b3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the combined DataFrame:\n",
            "                                                 msg\n",
            "0                                    Heyâ€¦ you awake?\n",
            "1                Yeah, can't sleep again. What's up?\n",
            "2  Just feeling... off, you know? Everything feel...\n",
            "3  I get it. Itâ€™s been the same for me. Every day...\n",
            "4  Exactly. Itâ€™s like Iâ€™m surrounded by people, b...\n",
            "\n",
            "Total number of messages: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting using trained model"
      ],
      "metadata": {
        "id": "urjBYgRaCiOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Load the model using pickle\n",
        "with open('/content/model_nb.pkl', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "# Define the prediction function\n",
        "def predict_status(sentence):\n",
        "\n",
        "    # Get prediction\n",
        "    prediction = model.predict([sentence])\n",
        "\n",
        "    # Apply threshold and return status\n",
        "    predicted_class = 1 if prediction[0] > 0.5 else 0\n",
        "    return 'NORMAL' if predicted_class == 1 else 'NOT NORMAL'\n",
        "\n",
        "# Apply the prediction function to DataFrames\n",
        "reddit_comments_df['res_status'] = reddit_comments_df['Comment'].apply(predict_status)\n",
        "subreddits_df['res_status'] = subreddits_df['Description'].apply(predict_status)\n",
        "wasap_msg_df['res_status'] = wasap_msg_df['msg'].apply(predict_status)"
      ],
      "metadata": {
        "id": "UqLfu35hDRLb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_overall_recommendation(dfs_dict):\n",
        "    total_normal = 0\n",
        "    total_not_normal = 0\n",
        "\n",
        "    # ANSI escape codes for colors\n",
        "    RED = \"\\033[91m\"\n",
        "    GREEN = \"\\033[92m\"\n",
        "    RESET = \"\\033[0m\"  # To reset the color back to default\n",
        "\n",
        "    # Calculate totals across all dataframes\n",
        "    for df_name, df in dfs_dict.items():\n",
        "        counts = df['res_status'].value_counts()\n",
        "        total_normal += counts.get('NORMAL', 0)\n",
        "        total_not_normal += counts.get('NOT NORMAL', 0)\n",
        "\n",
        "    # Print the counts with color formatting\n",
        "    print(f\"\\nTotal {GREEN}NORMAL{RESET} messages across all platforms: {GREEN}{total_normal}{RESET}\")\n",
        "    print(f\"Total {RED}NOT NORMAL{RESET} messages across all platforms: {RED}{total_not_normal}{RESET}\")\n",
        "\n",
        "    # Check if the \"NOT NORMAL\" count is 40% or more of the \"NORMAL\" count\n",
        "    if total_normal > 0 and (total_not_normal / total_normal) >= 0.4:\n",
        "        print(f\"\\n{RED}WARNING: The person may be prone to mental health issues (NOT NORMAL messages are 40% or more of NORMAL messages).{RESET}\")\n",
        "\n",
        "    # Make final recommendation based on the total counts\n",
        "    if total_normal > total_not_normal:\n",
        "        print(f\"\\nSTAGE-1 : FINAL ASSESSMENT: {GREEN}No major mental health concerns - normal.{RESET}\")\n",
        "    else:\n",
        "        print(f\"\\nSTAGE-1 : FINAL ASSESSMENT: {RED}Mental health concerns detected - doctor recommended.{RESET}\")\n"
      ],
      "metadata": {
        "id": "piMDBu7oDJZY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dictionary of dataframes\n",
        "dfs = {\n",
        "    'Reddit Comments': reddit_comments_df,\n",
        "    'Subreddits': subreddits_df,\n",
        "    'WhatsApp': wasap_msg_df\n",
        "}\n",
        "\n",
        "# Get overall recommendation with the new feature\n",
        "get_overall_recommendation(dfs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_aNG-GsDvTy",
        "outputId": "1b09e65c-79e1-4997-dcc9-9b874aaa531d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total \u001b[92mNORMAL\u001b[0m messages across all platforms: \u001b[92m47\u001b[0m\n",
            "Total \u001b[91mNOT NORMAL\u001b[0m messages across all platforms: \u001b[91m21\u001b[0m\n",
            "\n",
            "\u001b[91mWARNING: The person may be prone to mental health issues (NOT NORMAL messages are 40% or more of NORMAL messages).\u001b[0m\n",
            "\n",
            "STAGE-1 : FINAL ASSESSMENT: \u001b[92mNo major mental health concerns - normal.\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}